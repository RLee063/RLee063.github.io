---
layout: post

title: "智能化漏洞安全解决思路与参考方案"

---

**一、深度学习介绍**

深度学习是机器学习的一个子集，是一种用于建立并且模拟人脑，从而进行分析学习的神经网络，是通过模仿人脑的机制来解释数据的一种机器学习技术。在人的大脑中，信息通过神经元进行传递，神经元互相连接形成了一个庞大的结构，而深度学习则模拟了大脑中的神经元概念，并通过神经元的各种连接，形成一个神经网络，以达到信息传输的目的，从而进行数据的学习，解释以及预测。

深度学习的应用十分广泛，包括自然语言处理，自动驾驶技术，数据挖掘技术，多语言翻译等等。深度学习起源于传统 BP(Back Propagation) 神经网络，主要分为卷积神经网络 (CNN) 和循环神经网络 (RNN) 等。卷积神经网络多用于图像的处理，循环神经网络多用于对序列数据的处理。

**1.1 BP**  **神经网络**

BP 神经网络是一种前馈神经网络，它使用误差反向传播算法来进行模型训练。通过大量样本数据的训练，不断修正其中的网络节点权值和阈值，使得神经网络的误差沿负梯度方向下降，从而逼近期望输出。BP 神经网络模型是一种应用较为广泛的神经网络模型，多用于数据压缩，函数逼近，模型识别分类和时间序列预测等。如图2-2所示，其基本结构为包含多个节点的输入层，输出层，以及具有多个层次，多个节点的使用多种方式连接的隐藏层。简单来说，就是多层神经元的组合网络结构，其中每一层神经元包含多个节点，层与层之间的节点互相连接。

![](RackMultipart20211118-4-yoyl9d_html_81831479c53a10f3.png)

图1-1 神经网络基本结构

BP 神经网络主要可以分为两个过程，第一个是信号的前向传播，信号从输入层进入，经过隐藏层，最后传播到输出层，第二个是误差的反向传播，即从输出层方向传播到隐藏层，最后到输入层。在误差反向传播的过程中，BP 算法依次调节各个神经元的权重和阈值，最终完成模型的训练。

**1.2**  **卷积神经网络**

卷积神经网络 (Concurrent Nerual Network, CNN) 是一种带有卷积结构的深度神经网络，最早是为了进行图像预处理而设计出的一种模型。CNN 网络一般包括：(1) 输入层，通常是输入的图片等数据。(2) 卷积层，包含用于卷积计算的过滤器。当给定一张新图时，CNN 并不能准确地知道这些特征到底要匹配原图的哪些部分，所以它会在原图中把每一个可能的位置都进行尝试，相当于把这个特征变成了一个过滤器。(3) 池化层，用于缩减矩阵，减少参数数量。对于图片来说，池化就是将输入图像进行缩小，减少像素信息，只保留重要信息。(4) 全连接层，即全连接的神经网络，在整个卷积神经网络中起到分类器的作用，即通过卷积，池化等过程后，再经过全连接层对结果进行识别分类。(5) 输出层，用于分类输出。卷积神经网络本质上是一种从输入到输出的映射，它能够学习大量的输入与输出之间的映射关系，而不需要任何输入和输出之间的精确的数学表达式，只要用已知的模式对卷积网络加以训练，网络就具有输入输出对之间的映射能力。由于 CNN 的特征检测层能够通过训练数据进行学习，所以在使用 CNN 时，特征可以隐式地从训练数据中进行学习，不需要显式抽取。另外，由于在同一特征映射面上，各个神经元的权值相同，因此卷积神经网络可以并行学习。这也是卷积网络相对于其他相互连接的神经网络一大优势。

**1.3**  **循环神经网络**

循环神经网络 (Recurrent Neural Network, RNN) 是深度学习中的一种模型，相较于普通的神经网络，它更善于挖掘和利用数据中的时序信息以及语义信息的深度表达能力，并在语音识别，语言模型，机器翻译以及时序分析等方面实现了突破。循环神经网络主要用于处理和预测序列数据。序列数据的一大特点就是数据前后的关联性。在普通的神经网络中，层与层之间的节点是互相连接的，然而同一网络层的节点之间却是互不关联的。因此，它不能够很好的表达在同一层的节点的关联性，即序列数据的前后关联性。循环神经网络是具有时间联结的前馈神经网络，它们有了状态，通道与通道之间有了时间上的联系。神经元的输入信息，不仅包括前一神经细胞层的输出，还包括它自身在先前通道的状态，如图1-2所示，左侧图形就是 RNN 模型的基本结构，而右侧就是它在时间上进行展开的示意图。是时刻t的输入，相应的，分别是对应时刻t的隐藏层和输出层。

![](RackMultipart20211118-4-yoyl9d_html_85cf092ebc5ffd9a.png)

图1-2 RNN 模型基本结构

RNN 基本模型的主要问题在于梯度爆炸和消失。同时，在前向过程中，开始时刻的输入对后面时刻的影响越来越小，这就是长距离依赖问题。在生物体中，神经元拥有对过去时序状态很强的记忆能力。而 RNN 中的长距离依赖问题则导致该神经网络失去了记忆的能力。

而后提出的长短期记忆 (Long-Short Term Memory, LSTM) 模型就是要解决这两个问题，该模型通过引入若干门来解决，相比 RNN 多了一个状态。这个状态用于承载着之前所有状态的信息。每到新的时刻，就有相应的操作根据这个状态来决定舍弃什么旧的信息以及添加什么新的信息。由此完成信息的选择性舍弃和保留，从而进行有选择的记忆。

**二、将深度学习用于漏洞检测**

最近在自然语言处理（NLP）领域的突破，如机器翻译和语言理解，也证明了神经网络模型在理解文本/语言数据的潜在丰富&quot;语义&quot;方面的能力。此外，早期研究人员发现自然语言模型对处理软件源代码也很有效，这促使许多研究人员将深度学习技术应用于漏洞检测任务。

1. **促进表征学习的神经模型**

在以往的研究中，不同类型的网络结构用于从各种类型的输入中提取抽象特征，也称之为特征表示，用于识别易受攻击代码片段的语义特征。

1. 全连接网络（FCN）：FCN也称为多层感知器（MLP），许多先驱研究人员选择它作为主要基于手工数字特征的漏洞检测模型。这类工作将网络视为一个高度非线性的分类器，用于学习隐藏的和可能复杂的脆弱模式。与传统的ML算法（如随机森林、支持向量机（SVM）和C4.5）相比，FCN可以拟合高度非线性和抽象的模式。这得到了普适逼近定理的支持，即一个具有一个隐藏层和有限个神经元的FCN可以逼近任何连续函数。因此，在存在较大数据集的情况下，FCN有可能比传统的ML算法获得更丰富的模型。这一潜力促使研究人员将其用于建模潜在且复杂的易受攻击的代码模式。FCN的另一个优点是&quot;输入结构不可知&quot;，这意味着网络可以采用多种形式的输入数据（例如图像或序列）。这也使研究人员能够灵活地手工制作各种类型的功能，以供网络学习。
2. 卷积神经网络（CNN）：CNN旨在学习结构化空间数据。在图像处理中，CNN第一层的过滤操作能够从语义相似的邻近像素中学习特征。然后，后续的过滤器将学习更高级别的特征，这些特征将被后续层（即致密层）用于分类。 CNN 能够从附近像素中学习特征的能力也有助于 NLP 任务。例如，在文本分类任务中，应用于上下文窗口（即包含少量词嵌入）的 CNN 过滤器可以将上下文窗口内的词投影到上下文特征空间中的局部上下文特征向量，其中语义相似词的向量位于近距离。因此，CNN 可以捕获单词的上下文含义，这促使研究人员应用 CNN 来学习上下文感知的易受攻击的代码语义。
3. 循环神经网络：与前馈网络（例如 FCN 或 CNN）相比，RNN 自然是为处理序列数据（例如文本）而设计的。因此，大量研究应用 RNN 的变体来学习漏洞的语义。特别是，RNN 的双向形式能够捕获序列的长期依赖性。为此，许多研究利用双向 LSTM(Bi-LSTM)和门控循环单元 (GRU)结构来学习代码上下文相关性，这对于理解许多类型的漏洞（例如，缓冲区超限运行）。这些漏洞与包含多个连续或间歇代码行的代码上下文相关，这些代码行构成了易受攻击的上下文。
4. 杂项类型：有一些漏洞检测研究应用于其他不适合上述类型的网络结构，例如深度信念网络 (DBN) 和变分自编码器 (VAE) 。深度学习技术的另一个有前途的特点是可以定制网络结构以适应不同的应用场景。例如，研究人员应用了内存网络，该网络配备了外部内存&quot;插槽&quot;，用于存储先前引入的信息以供将来访问。与LSTM结构相比，这种类型的网络能够捕获更长范围的序列依赖性；因此，它具有更强的捕获更长范围的代码序列的能力，这对于识别缓冲区溢出漏洞是上下文相关的来说是十分关键的。

1. **以前的工作分类**

我们将以前的的研究分为四类特征表示，总结如下。

1. 基于图的特征表示：大量的研究应用DNNs从不同类型的基于图的程序表示中学习特征表示，包括AST、CFG、PDG以及它们的组合。
2. 基于序列的特征表示：这一类的研究利用DNN从序列的代码实体中提取特征表示，如执行轨迹、函数调用序列和变量流/序列。
3. 基于文本的特征表示：对于这一类工作，特征表示直接从代码的表层文本中学习。
4. 混合特征表示：这一类包括最近结合上述三种特征表示的研究。

提出分类的背后有两方面的理由。一方面，这些研究的贡献在于如何处理软件代码，以产生有利于DNN理解代码语义的特征表示，并捕获作为潜在脆弱代码片断指标的模式。另一方面，DNN模型作为一个分类器，具有内置的代表学习能力。现有的研究是基于不同类型的特征输入，允许DNN获得揭示不同语义信息的高级表征。例如，使用ASTs作为神经模型输入的研究使得DNNs能够通过程序的层次结构捕获代码模式和语义。应用函数调用序列的研究允许DNNs学习与函数调用模式相关的抽象特征。

1. **基于图的特征表示**

本节介绍使用各种类型的基于图形的程序表示的研究，包括AST、CFG、PDG和数据依赖图（DDG）作为DNN的输入，用于学习深度特征表示。

L. K. Shar等人在&quot;Predicting SQL injection and cross site scripting vulnerabilities through mining input sanitization patterns&quot;一文中提出了一种检测基于PHP的Web应用程序的SQL注入（SQLI）和跨站脚本（XSS）漏洞的方法。这是一个针对语句级检测的细粒度的解决方案。该方法的动机是观察到输入消毒代码的实施对于预防SQLI和XSS漏洞至关重要。基于这一观察，他们提出了一套静态代码属性，用来描述CFG和DDG的净化代码模式。具体来说，作者用CFG确定了输入和它们对应的汇，以产生输入属性，DDG被用来定位执行输入消毒的函数。基于确定的消毒功能，作者对一些消毒属性进行了分类。这些静态代码属性形成了20-D的特征向量，用来描述消毒模式。然后，作者应用C4.5、Naive Bayes（NB）和FCN作为分类器进行训练和分类。他们的实证研究表明，在检测SQLI漏洞方面取得了93%的召回率和11%的误报率的平均结果，这比XSS漏洞的预测结果（78%的召回率和6%的误报率）稍好一些。

第一项研究是在S. Wang等人的论文&quot; Automatically learning semantic features for defect prediction&quot;中提出的，他们利用ASTs学习神经表示从Java源代码中检测缺陷和漏洞。假设AST代表了包含编程模式的代码语法，而隐藏在源代码中的代码语义可以通过解析AST来揭示。当从源代码中提取AST时，作者保留了三种类型的节点：1）函数调用和类实例创建的节点；2）声明的节点；以及3）控制流的节点。然后，这些节点被转换为标记序列。在跨项目检测的情况下，项目特定的标记被一般的名称所取代，如方法声明/调用。具体来说，作者引用了一种距离相似性计算算法来消除数据中的噪声。该算法能够根据token和token之间的顺序计算token序列之间的距离。此后，使用k-NN算法计算距离。如果某个实例与其邻居具有相反的标签，则该实例将被标记为噪声并删除。最后，使用一对一对剩余的标记序列进行标记映射表将每个标记映射到一个整数，以便序列可以用作 DBN 的输入。作者将样本馈送到训练过的 DBN 以自动生成高级特征表示，然后将其用于训练传统的 ML 算法，例如ADTree、NB 和逻辑回归 (LR)。为了评估项目内检测，作者从 PROMISE 缺陷库中选择了 Java 项目，并将他们提出的方法与两个不同的功能集进行了比较：1) 软件指标和 2) ASTs。结果表明，DBN 生成的基于 AST 的特征在所有选择的项目上都取得了最佳性能。对于跨项目场景，作者选择了TCA+作为基线系统。 性能评估表明，在 22 个跨项目场景中，有 17 个基于 DBN 的方法在 F1 分数方面优于 TCA+。

G. Lin等人在&quot;POSTER: Vulnerability discovery with function representation learning from unlabeled projects&quot;中提出的另一种基于AST的方法应用BiLSTM网络来学习跨项目漏洞发现的特征表示。考虑到获取易受攻击函数的手动标签在实践中可能会很昂贵，作者利用可以自动生成为代理的软件复杂性度量来替代实际标签，以在函数级别生成高级表示。该方法建立在许多研究共享的假设基础上，即使用软件代码度量（例如，代码复杂性度量）作为漏洞检测的特征，因为复杂代码难以测试和维护；因此，它更有可能是脆弱的。

1. **基于序列的特征表示**

G. Grieco等人在文章&quot;Toward large-scale vulnerability discovery using machine learning&quot;中提出的一种方法利用从静态和动态分析中提取的轻量级特征来预测二进制级别的操作系统 (OS) 规模程序中的内存损坏漏洞。假设是来自静态和动态分析的调用序列/跟踪可以揭示表现出内存损坏漏洞的 C 库函数的使用模式。作者从一组与标准 C 库函数关联的调用序列中提取静态特征，这需要作者反汇编二进制文件。获得动态特征需要在有限的时间段内执行程序。在执行过程中，作者监控程序的事件并收集调用序列。然而，获得的动态调用序列中包含了大量函数调用的参数，这些参数是低级计算值。作者需要将它们分为子类型以减少参数类型的多样性。随后，作者应用 N-gram 语言模型和 Word2vec将文本序列转换为有意义的向量表示，然后将其馈送到三个分类器：LR、FCN 和随机森林进行训练、验证和测试。

F. Wu 等人在&quot;Vulnerability detection with deep learning&quot;一文中对 C 程序漏洞检测进行了评估研究，以比较不同类型的 DNN 在从动态函数调用序列中提取的特征集上的性能。选择了四种类型的网络结构进行评估：&quot;Convolutional neural networks for sentence classification&quot;中提出的 CNN 网络、仅包含一个 LSTM 层的 LSTM 网络、分别具有一个卷积层和一个 LSTM 层的 CNN-LSTM 网络以及具有两个隐藏层的 FCN。作者收集了 9872 个二进制格式的 32 位 Linux 程序，并应用G. Grieco等人介绍的方法通过允许程序在有限的时间段内执行来获取 C 标准库函数调用序列。然后，作者遵循G. Grieco等人采用的方法，通过使用提取函数的参数的子类型来减少参数类型的多样性。接下来，作者使用Keras提供的标记化工具，这是一个深度学习框架，通过用唯一的整数替换每个标记，将函数调用序列转换为数字序列。填充和截断还用于将各种长度的序列转换为 25 个标记的固定长度。最后，作者将 9872 程序数据集以 8:1:1 的比例划分为训练集、验证集和测试集。为了将输入序列馈送到网络，添加了一个嵌入层作为三个网络的第一层，以将输入数字调用序列中的每个标记转换为固定长度的向量。评估结果表明，LSTM 网络的误报率最低（19%），CNN-LSTM 网络在 F-Score 方面的表现优于其他网络，达到 83.3%。

Z. Li等人在&quot;Vuldeepecker: A deep learning-based system for vulnerability detection&quot;中提出的一种方法利用称为&quot;代码小工具&quot;的程序表示来检测缓冲区错误和资源管理错误漏洞。代码小工具是一系列连续或间歇的代码行，它们在语义上相互关联，形成一系列描述变量流和数据依赖关系的语句。具体来说，根据本文，代码的语义关系定义为数据依赖或控制依赖。因此，代码小工具定义了许多代码行，这些代码行暗示存在漏洞，并且可以被数据流或控制流依赖项捕获。为了提取与数据流或控制流相关的库/API调用和相应的程序片，作者使用了一个名为Checkmarx的商业工具。然后，将提取的程序片段组装成一个代码小工具，表示完整的数据流和/或API调用序列。随后，作者将代码小工具中的程序片段转换为令牌序列，并应用Word2vec将其转换为固定长度的向量表示。BiLSTM网络被用作基于代码小工具特征的漏洞检测分类器。

最近的一项研究&quot;µVulDeePecker: A deep learning-based system for multiclass vulnerability detection&quot;通过合并&quot;代码小工具&quot;进一步扩展了 Vuldeepecker，不仅包含描述数据依赖关系的代码序列，还包含揭示控制依赖关系的代码序列。因此，代码序列形成了捕获与可能的漏洞相关的&quot;全局&quot;语义的上下文。为了检测特定的漏洞类型，他们还提出了所谓的&quot;代码注意力&quot;，将注意力集中在&quot;特定库中的参数或API调用&quot;等语句中的&quot;本地化&quot;信息上。基于语义的特征和基于&quot;局部&quot;语义的特征，他们提出了两个具有相同设置但规模不同的深度 Bi-LSTM 网络。最终，他们使用 一个merge层来融合全局和局部特征。然后，融合的特征表示被传递到另一个 Bi-LSTM 层，然后是一个 softmax 层进行分类。

1. **基于文本的特征表示**

H. Perl 等人在&quot;VCCFinder: Finding potential vulnerabilities in open-source projects to assist code audits&quot;中提出的最新方法将 Java 源文件转换为文本token列表，并应用 N-gram 模型将标记转换为向量。他们假设可以通过挖掘源代码令牌的频率来识别易受攻击的模式。为了在使用 N \&gt; 2 的 N-gram 模型时处理所得特征向量的高维，他们通过应用 Wilcoxon 提出的rank-sum过滤不相关特征来降低特征向量的维数来执行特征选择。 作者将特征向量馈送到深度FCN 和实现的最佳性能是平均 93% 的检测准确率，97.6% 的准确率和 89.26% 的数据集召回率。

Y. J. Lee等人在&quot;Learning binary code with deep learning to detect software weakness&quot;中引入的另一种基于 CNN 的方法用于在程序集级别检测 C 程序漏洞，旨在直接从程序集指令中捕获易受攻击的代码模式。为了将汇编指令转换为向量表示，作者开发了 Instruction2vec，它基于 Word2vec实现。 Instruction2vec 通过将四种类型的汇编代码——操作码、寄存器、指针值和库函数——映射到相应的固定长度的密集向量来生成汇编代码查找表。

R. Russell等人在&quot;Automated vulnerability detection in source code using deep representation learning,&quot;中提出了一种类似的方法，该方法将 CNN 应用于功能级漏洞检测。作者从 Juliet 测试套件、Debian Linux 发行版和 GitHub 中收集了 1200 万个源代码功能样本。作者实现了一个自定义的 C/C++ lexer 来解析源代码，将函数源代码转换为 token 序列。为了捕获关键 token 的含义并最小化 token 词汇量，词法分析器仅使用 156 个 token 来表示源代码。这意味着，除了所有的 C/C++ 关键字、运算符和分隔符之外，不影响编译的代码都被剥离了。然后，作者应用可训练嵌入将函数序列中的每个标记转换为固定的 k 维表示，以便在网络训练阶段通过反向传播对每个标记的嵌入进行微调。作者应用了两个网络进行自动特征提取：1）&quot;Convolutional neural networks for sentence classification&quot;中提出的 CNN 结构具有一个卷积层，后跟一个最大池化层和一个两层 GRU 网络，然后是一个最大池化层。在网络训练阶段，对整个网络进行训练。当训练过程完成时，作者将训练和测试数据输入到训练好的网络中，并获得两个网络最大池化层的输出作为学习到的特征，称为神经表征。然后，神经表示被用作随机森林分类器的输入，以进行进一步的训练和测试。实验表明，与直接使用两个网络作为分类器相比，使用网络作为特征生成器加上随机森林分类器产生了更好的检测性能。

最近的一项研究提出了一种基于 VAE的最大散度序列自动编码器 (MDSAE)，用于从机器指令序列中自动学习表示，以检测二进制级别的漏洞 [52]。作者为每个类（脆弱类和非脆弱类）应用了两个可学习（非固定）高斯先验，并且来自潜在空间的代码在分布之前拟合到数据中。然后，散度 [例如，Wasserstein ( WS）距离或Kullback–Leibler（KL）散度]这两个先验之间的距离最大化以分离脆弱类和非脆弱类的表示。

1. **混合特征表示**

F. Dong在&quot;Defect prediction in Android binary executables using deep neural network&quot;中提出了一种检测 Android 二进制可执行文件中漏洞的方法。具体来说，作者对Android APK文件进行反编译，得到包含dalvik指令包的smali文件。从 smali 文件中提取了两种类型的特征：1）用 dalvik 指令的频率表示的token特征，显示了token属性；2）通过遍历 smali 文件的 AST 生成的语义特征。为了提取令牌特征，作者将smali文件的dalvik指令分为八类，并建立了映射表。通过在映射表中记录指令的频率获得令牌特征。语义特征是从使用 antlr 从 smali 文件解析的 AST 中提取的。作者应用深度优先搜索 (DFS) 遍历将 AST 转换为序列。然后，基于之前构建的dalvik指令映射表将得到的AST序列转换为整数序列。最后，结合token特征和语义特征向量构建特征向量，并馈送到深度FCN进行训练和测试。作者还对深度 FCN 和其他传统 ML 算法（包括 SVM、NB、C4.5 和 LR）进行了比较。他们的实证结果表明，深度 FCN 优于其他算法，达到了 85.98% 的 AUC。

J. A. Harer等人在&quot;Automated software vulnerability detection with machine learning&quot;中提出的另一种方法是基于两组用于漏洞检测的特征。第一组是直接从源代码中提取的基于源的特征，第二组是从 Clang 和低级虚拟机(LLVM)生成的 CFG 中导出的基于构建的特征。 具体来说，对于基于源的特征，作者实现了一个自定义的 C/C++ lexer，将源代码函数转换为标记序列，然后是程序。特别是，变量名被映射到相同的通用标识符，但单个函数内的每个唯一变量名都被分配了一个单独的索引以跟踪变量重新出现。然后，使用词袋模型和 Word2vec 模型将得到的标记序列转换为两种类型的向量表示。对于基于构建的特征，作者编译程序并从指令级的函数级CFG和基本块中提取特征。特征集由每个基本块中发生的操作以及变量的定义和使用组成。比如，作者构造了一个use-def矩阵来记录变量的定义和使用。如果在指令中定义了一个变量并在指令 j 中使用，则 use-def 矩阵的 (j, i) 项都设置为 1。结果特征集包含邻接矩阵和 op-vec/use-def 向量。然后，作者定义了一个手工制作的固定大小的向量，通过执行平均操作来容纳 CFG 的邻接矩阵和 op-vec/use-def 向量。

G. Lin等人在&quot;Software vulnerability discovery via learning multi-domain knowledge bases&quot;中提出的框架利用两个 Bi-LSTM 网络从两种不同类型的数据源中获取特征表示，以弥补标记数据的不足。该框架允许每个网络独立训练并用作特征提取器，用于从两个漏洞相关数据源的组合中学习漏洞模式的潜在表示，这些数据源是 SARD项目包含合成的漏洞测试用例和真实世界的漏洞数据来源。为了弥合真实世界样本和来自 SARD 项目的合成样本之间的差异，作者应用了两种不同类型的特征表示：从现实世界样本中提取的 AST 和合成样本的源代码。然后，一个网络接受 AST，另一个网络在训练阶段将源代码作为输入。他们假设，与使用单个数据源训练的隔离网络相比，两个训练的网络能够从两个与漏洞相关的数据源中获取更多的&quot;漏洞知识&quot;。在训练阶段之后，他们使用来自目标软件项目的可用标记数据，并将它们馈送到两个经过训练的 Bi-LSTM 网络，分别获得两组高级表示。随后，将获得的表示连接起来形成聚合特征集，可用于训练常规 ML 分类器，例如随机森林。 他们的实证研究证明，使用两个漏洞相关数据源的框架比仅使用一个数据源更有效.该框架在 FFmpeg、LibTIFF 和 LibPNG 项目上的表现优于他们之前的工作。